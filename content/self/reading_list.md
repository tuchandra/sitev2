+++
title = "Reading List"
date = 2020-01-02
draft = false
categories = ["self"]
url = "/reading"
hidden = "true"
+++

This is a page of things I'm hoping to read "soon" (for some value of soon). It's some cross between a digital bookshelf and public bookmarks, where I drop papers that cross my radar or blog posts, talks, or other ideas.

Some of these I've printed out and carry around with me. Others are unlikely to ever be read because they're so far out of my areas of expertise or interest. While this page is mostly for my own reference, it also pretty broadly shows the types of work I'm interested in.

<!--more-->

## Papers
[The Measure and Mismeasure of Fairness: A Critical Review of Fair Machine Learning](https://5harad.com/papers/fair-ml.pdf) by Sam Corbett-Davies, Sharad Goel

[The risk of racial bias in hate speech detection](https://homes.cs.washington.edu/~msap/pdfs/sap2019risk.pdf) by Maarten Sap, Dallas Card, Saadia Gabriel, Yejin Choi, Noah A. Smith (ACL 2019)

[On the Utility of Learning about Humans for Human-AI Coordination](https://arxiv.org/pdf/1910.05789.pdf) from BAIR, NeurIPS 2019

[Towards fairer datasets: filtering and balancing the distribution of the people subtree in the ImageNet hierarchy](https://arxiv.org/abs/1912.07726) from FAT* 2020

[Generative models for effective ML on private, decentralized datasets](https://research.google/pubs/pub48690/) from Google on federated learning

[Gelman: progress from the past decade](https://statmodeling.stat.columbia.edu/2020/01/01/progress-in-the-past-decade/) is a list of tons of papers on his blog

[Generalizable and robust TV advertising effects](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3273476) linked from the correspondent

[Beyond near and long term: something about AI ethics and society](https://arxiv.org/abs/2001.04335) from Import AI

[Glassdoor Culture paper](https://vedantswain.com/papers/CHI20_GlassdoorCulture.pdf) from CHI 2020, De Choudhary lab

[The stealth media? Groups and targets behind divisive issue campaigns on Facebook](https://journalism.wisc.edu/wp-content/blogs.dir/41/files/2018/04/Kim.FB_.StealthMedia.re_.3.two-colmns.041718-1.pdf) from Network Propaganda

[Weaponizing the digital influence machine: the political perils of online ad tech](https://datasociety.net/wp-content/uploads/2018/10/DS_Digital_Influence_Machine.pdf) on digital political advertising

[WES: Agent-based User Interaction Simulation on Real Infrastructure](https://research.fb.com/wp-content/uploads/2020/04/WES-Agent-based-User-Interaction-Simulation-on-Real-Infrastructure.pdf?) from Facebook


## CHI 2020
Based on the following sources:
 * [Ali Alkhatib](https://ali-alkhatib.com/blog/chi-2020-reading-list): A (tentative) CHI Reading List
 * [CHI 2020 Best Papers & Honorable Mentions](https://chi2020.acm.org/for-attendees/chi-2020-best-papers-honourable-mentions/)
 * [Full Proceedings](https://dl.acm.org/doi/proceedings/10.1145/3313831)
 * [UW Interactive Data Lab](https://idl.cs.washington.edu/papers)

It would be great to find a webpage of the proceedings that isn't a huge PDF, ouch.

Papers I have already identified:
 * [Computing Students' Learning Difficulties in HCI Education](https://alannaholeson.com/papers/chi2020_HCILearningDiffs_final_tagged.pdf) by Alannah Oleson, Meron Solomon, Amy J. Ko
 * Data Everyday: Data Literacy Practices in a Division I College Sports Context by Tamara Clegg, Daniel M. Greene, Nate Beard, Jasmine Brunson (can't find link)
 * [Wrex: A Unifed Programming-by-Example Interaction for Synthesizing Readable Code for Data Scientists](https://www.microsoft.com/en-us/research/uploads/prod/2020/03/chi20c-sub4932-cam-i16.pdf) by Ian Drosos, Titus Barik, Philip J. Guo, Robert DeLine, Sumit Gulwani
 * [What is AI Literacy? Competencies and Design Considerations](https://static1.squarespace.com/static/53c69580e4b08011fc2337bf/t/5e2893e4a9d342214836e832/1579717605435/CHI+2020+AI+Literacy+Paper-Camera+Ready.pdf) by Duri Long, Brian Magerko
 * the Interpreting Interpretability paper that I [already read]({{< ref "papers/interpreting_interpretability_kaur.md" >}}) :)
 *  "On Finsta, I can say 'Hail Satan'": Being Authentic but Disagreeable on Instagram by Lee Taber and Steve Whittaker
 * Understanding and Visualizing Data Iteration in Machine Learning by FredHohman, Kanit Wongsuphasawat, Mary Beth Kery, Kayur Patel

More when I'm not so sleepy.


## Blog posts
[Commentary: Andy Jassy aims to reinvent Amazon Web Services for the cloud’s next generation](https://siliconangle.com/2019/12/01/commentary-andy-jassy-aims-reinvent-amazon-web-services-clouds-next-generation) from SiliconAngle (what?), an interview with Andy Jassy, the cloud chief at AWS.

Most things on [this course project page](https://courses.cs.washington.edu/courses/cse492e/20wi/project.html), found from the author of the Skynet Today article

[The coming software apocalypse](https://www.theatlantic.com/technology/archive/2017/09/saving-the-world-from-code/540393/) from The Atlantic. I've already read this, but worth revisiting.

[How Git works, from the inside out](https://codewords.recurse.com/issues/two/git-from-the-inside-out?). Detailed essay on the graph structure of Git, for someone already familiar with how to use it. Very long.

[FAIR blog post](https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system) on insta recommendations, from Miranda

[An epidemic of AI misinformation](https://thegradient.pub/an-epidemic-of-ai-misinformation) from Data Elixir

[Testifying at the Senate about A.I.‑Selected Content on the Internet](https://writings.stephenwolfram.com/2019/06/testifying-at-the-senate-about-a-i-selected-content-on-the-internet/) by Steven Wolfram

[What's my data worth?](https://bair.berkeley.edu/blog/2019/12/16/data-worth/) from BAIR by Ruoxi Jia

[Overcooked blog post by BAIR what?](https://bair.berkeley.edu/blog/2019/10/21/coordination/), from Judah

[The no code delusion](https://www.alexhudson.com/2020/01/13/the-no-code-delusion/) from Reddit

[Mercurial's journey to Python 3](https://gregoryszorc.com/blog/2020/01/13/mercurial%27s-journey-to-and-reflections-on-python-3/) from Reddit again

[Engineering consent](http://classes.dma.ucla.edu/Fall07/28/Engineering_of_consent.pdf)

[White House memo on AI regulation](https://www.whitehouse.gov/wp-content/uploads/2020/01/Draft-OMB-Memo-on-Regulation-of-AI-1-7-19.pdf)

[Honest causal forests](https://www.markhw.com/blog/causalforestintro) from Lee

[How will you measure your life?](https://hbr.org/2010/07/how-will-you-measure-your-life) by Clayton Christensen


### More In Common + related articles
[NYT college outcomes](https://www.nytimes.com/interactive/projects/college-mobility/northwestern-university)

[Hidden Tribes report](https://static1.squarespace.com/static/5a70a7c3010027736a22740f/t/5bbcea6b7817f7bf7342b718/1539107467397/hidden_tribes_report-2.pdf) LONG

[Hidden Tribes](https://hiddentribes.us/)

[The Perception Gap](https://perceptiongap.us/)


## Books
[The Twenty-Six Words That Created The Internet](https://www.jeffkosseff.com/home) by Jeff Kosseff


## Talks
[Getting specific about algorithmic bias](https://www.youtube.com/watch?v=S-6YGPrmtYc) by Rachel Thomas, from the USF Center for Applied Data Ethics. Found from Twitter, the author of the [biased algorithms NYT article](https://www.nytimes.com/2019/12/06/business/algorithm-bias-fix.html) (Sendhil Mullainathan) retweeted. Also the [Twitter chain](https://twitter.com/math_rachel/status/1191069453389189122).


## Post ideas
Brains are black boxes, too - something that Kidd said in the [2020 predictions](https://venturebeat.com/2020/01/02/top-minds-in-machine-learning-predict-where-ai-is-going-in-2020/) article

Who is responsible for (mis)use of tools? The OpenAI debate about GPT2, other advances in language models, deepfakes, etc ... Kidd talked about this in the article above too.
