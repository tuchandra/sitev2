+++
title = "What I read this week (March 22 - March 28)"
date = "2020-03-28"
categories = ["what I read"]
draft = false
+++

This week's reading focuses on TODO.


<!--more-->

## [Suggestions for writing NeurIPS 2020 broader impact statements](https://medium.com/@BrentH/suggestions-for-writing-neurips-2020-broader-impacts-statements-121da1b765bf)
**Author**: Brent Hecht

NeurIPS will now require authors to submit "broader impact" statements, "including possible societal consequences---both positive and negative" (from [Getting Started with NeurIPS 2020](https://medium.com/@NeurIPSConf/getting-started-with-neurips-2020-e350f9b39c28)). This is a suggestion that Hecht [suggested](https://acm-fca.org/2018/03/29/negativeimpacts/) two years ago as part of the Future of Computing Academy.

His advice is basically to start thinking about the broader impacts *now*, and draw upon the literature in CHI or FAccT (formerly FAT*) for ideas n how to do this. Thinking about the broader impact early will let you pivot the project, or perhaps choose a different one entirely. It might also be good to bring a social scientist onto the research team.

Hecht also suggests that the reviewer's job is not to judge submissions for their impacts, but rather to "evaluate the rigor with which they disclose their impacts." It'll take some time to figure out how to do this well, he argues, and some iteration and dialogue about this is essential.

**Thoughts**: It is very cool to see that the leading AI conference is going to mandate that authors devote space in their papers to this; field-wide change comes from the top. I am sure that it will receive criticism for papers whose broader impact is not always apparent---e.g., for new layer design, a new form of normalization, or other more mathematical results---but, to me, that's fine. That's an opportunity to think about these issues in more depth and iterate for future years.

Additionally, Brent was one of my professors at Northwestern. I was fortunate to take two classes with him, including one of my top-3 favorite classes, [Algorithms and Society Seminar](http://www.psacomputing.org/algsoc/schedule/). I am grateful to him for helping me to land in data science, for guiding my interest in AI ethics, and for generally helping me to shape how I think about the problems in this field. Seeing this post from him and his colleagues is great!


## [It's time to do something: Mitigating the negative impacts of computing through a change to the peer review process](https://acm-fca.org/2018/03/29/negativeimpacts/)
**Authors**: Brent Hecht, Lauren Wilcox, Jeffrey Bigham, Johannes Schoning, Ehsan Hoque, Jason Ernst, Yonatan Bisk, Luigi De Russis, Lana Yarosh, Bushra Anjum, Ddanish Contractor, Cathy Wu

**Summary**: ...





## Other, shorter articles
[Building a more accurate time service at Facebook scale](https://engineering.fb.com/production-engineering/ntp-service/) is an article from Facebook engineering talking about how they built a service (time.facebook.com) to sync time across many computers at sub-millisecond precision. The post starts by describing why leap seconds are awful, and the most popular approach for handling them is to "smear" the second across multiple hours. They go into great detail about their four-layer architecture and make me thankful that I have chosen a career in which I will never have to build a time service myself.

---

[Opinion | The right way to fight fake news](https://www.nytimes.com/2020/03/24/opinion/fake-news-social-media.html) in the NYT, written by Dr. Gordon Pennycook and Dr. David Rand, writes that anti-misinformation strategies need to be empirically grounded, and that many strategies in use today are not:
 * The "information panels" on YouTube (when content was government-funded) and "context" on Facebook have virtually no impact on whether people believed headlines
 * Adding messages that content is disputed by fact checkers is also challenging, because the *absence* of this warning leads people to believe that the content was verified, when usually it means the content was unchecked
 * General anti-misinformation campaigns ("fake news is not your friend" billboards) can reduce confidence in *all* news, which is ironically the goal of disinformation campaigns in the first place

The point, the authors write, is that you need to test your ideas. These were great examples of intuitively reasonable ideas that end up failing in practice.

---
