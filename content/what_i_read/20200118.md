+++
title = "What I read this week (January 12 - 18)"
date = "2020-01-18"
categories = ["what I read"]
draft = false
+++

Articles I read this week, including "goodbye clean code," the Neural ODEs paper retrospective, and TODO. <!--more-->

## [Goodbye, clean code](https://overreacted.io/goodbye-clean-code/)
**Author**: Dan Abramov

**How I found this**: from /r/programming

**Summary**: this is a retrospective on how the author (years prior) made a code change that theoretically made the code "cleaner," by most definitions of the word. In hindsight, the abstractions that they added (which are usually the tradeoff for cleaner code) were unnecessary and made it harder to change the requirements (while, yes, reducing duplication). The author's boss pulled him aside the next morning to ask him to revert the changes.

**Thoughts**: the more I think about this, the more I think the post misses the point. The clean code isn't the problem here: the problems are (1) the author making a code change without consulting the original author (where was code review? why did he commit overnight?) and (2) the author not recognizing that the requirements would change in the future. The original code wasn't great, and I *do* think it needed refactoring (make helper functions for the math?), but not in the author's way. Yes, abstractions have tradeoffs, but the problem wasn't caused by abstractions in the general sense--it was caused by the use of lousy abstractions. Reducing code duplication has been one of the most effective ways for me to untangle complex codebases.

**Sidenote**: originally, my "thoughts" paragraph was me just summarizing the article. After thinking some more about it, and reading some of the discussion that happened on [Reddit](https://old.reddit.com/r/programming/comments/eng355/goodbye_clean_code/), I switched course and decided that I don't really like this blog post at all. Disagreeing publicly is tough, though, and I felt a strange pressure to just rehash the important points and say "yeah, good stuff." Being able to criticize the post is harder.


## [Bullshit that I and others have said about Neural ODEs](https://www.youtube.com/watch?v=YZ-_E7A3V2w)
**Speaker**: David Duvenaud

**How I found this**: from /r/machinelearning

**Summary**: this is a research retrospective on the [Neural ODEs paper](https://arxiv.org/abs/1806.07366) that took place at NeurIPS 2019 (the original paper was at NeurIPS 2018). It's a short talk (20 minutes) and there isn't a lot to summarize. Some highlights include the stated motivation being more or less made up, handwaving the non-ML parts (delegating to ODE solvers), and some of the press coverage being misinformed. He Duvenaud brings up the contributions of nice visualizations and a clean title as contributing to the hype.

**Thoughts**: I don't understand this paper nearly well enough to comment on the substance, but I *really* appreciate the idea of research retrospectives. Reflecting on one's successes is not nearly as common as reflecting on failures, and watching this talk brings down a paper that received a lot of attention to a more ordinary level. It also reminds me that even these prolific papers have hacks and kludges, which Duvenaud discusses.
