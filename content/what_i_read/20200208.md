+++
title = "What I read this week (February 2 - February 8)"
date = "2020-02-08"
categories = ["what I read"]
draft = false
+++

Articles I read this week, including "an opinionated guide to ML research," advice for people interested in PhDs, and more. <!--more-->

## [An Opinionated Guide to ML Research](http://joschu.net/blog/opinionated-guide-ml-research.html)
**Author**: John Schulman

**How I found this**: /r/machinelearning

**Summary**: Schulman is a research scientist and founding member of OpenAI. This post is advice to aspiring researchers, and his keys to success are "working on the right problems, making continual progress on them, and achieving continual personal growth."

 * *Working on the right problems*: this is primarily advice on how to pick the right problems. Read a lot of papers (critically!), work in a group, talk to experienced researchers, and spend time reflecting on what is useful. He also discusses the differences between idea-driven and goal-driven research.
 * *Making continual progress*: this is advice on developing a long-term habit of problem solving. He suggests keeping a lab notebook with ideas, results, and what was worked on, and reviewing it periodically. He addresses the question of when to switch problems, and that in his experience switching too frequently is more often a problem than not switching enough.
 * *Personal development*: the author recommends reading textbooks (even outside of school, because they cover topics broadly) and PhD theses (which usually have lots of background information), along with seminal papers to understand the frontiers of the field. The "less exceptional" papers are also worth keeping an eye on to understand what ideas are being tried out.

**Thoughts**: there's a lot of great advice packed in here. Keeping a lab notebook has been extremely helpful to me in helping me remember what I've worked on and what ideas I have (or had ages ago). I like the strategy of reviewing the notebook into a summary every couple of weeks, since I feel like this would help me to maintain a coherent research direction.

The advice on switching problems also hits close to me. While my problems at work are defined by my team and the business, the methods I use aren't; and I can think of a couple of occasions when I was too quick to abandon a method that still showed a little bit of promise. I'm trying now to be more intentional about what ideas I try out and what I leave for later.

## [Advice to (prospective) grad students](https://blog.vivekhaldar.com/post/25136762019/advice-to-prospective-grad-students)
**Author**: Vivek Haldar

**How I found this**: no idea anymore

**Summary**: this is long post of advice to prospective CS PhDs (oh hello!). Some of the highlights are:

 * Be absolutely certain that you want a PhD. For going into academia, the odds are stacked against you. For going into industry, the financial opportunity cost is almost certainly not worth it when considering the 5+ years of missing a salary. "This is what I like to call a clamped decision. If you are not fully convinced that the answer is "yes", then the answer is "no.""
 * Choosing where to go is largely a function of happiness & quality of life + the learning & research you do. These, in turn, almost entirely depend on your advisor. Ask the current grad students who work with possible advisors. Oh, and location matters too.
 * On why to do a PhD: "Like I said above, this is a question of self knowledge. The circular answer is that **you should do it if you are the type of person who would enjoy it.**"

**Thoughts**: this is good advice, and mostly consistent with what I've heard before. I have done a great deal of self-reflection about whether or not grad school is for me, and I anticipate a lot more in the coming year. I think the biggest questions for me will be (1) do I want to devote 5+ years of my life to this, (2) can I pursue the opportunities I want right now (i.e., as a data scientist in industry), and (3) how much will this affect my personal life, relationships, and location. These are all worthy of deep thought.

## [What is life like for PhDs in computer science who go into industry?](https://blog.vivekhaldar.com/post/29296581613/what-is-life-like-for-phds-in-computer-science-who)
**Author**: Vivek Haldar

**How I found this** same blog as above

**Summary**: this is a series of short answers to questions about what it's like to be a CS PhD in industry (the author works at Google). The author opens with a discussion about the "industry research" model that was popularized by Google. Some of the answers are not PhD-specific (e.g., "how much mentoring is there" or how work-life balance is). The answer to "are you only qualified to work in the subfield you studied" is a resounding "no," which is consistent with my experiences at Nielsen.

**Thoughts**: this honestly doesn't have that much new information for me. I work with a lot of PhDs at my current job (my manager, one of two teammates, and many people who sit near me on other teams). In many ways, I'm doing the same things that they are. The author says as much--"you will usually do the same type of work"--so the real question is whether this is really what I want to do.

## [Why private micro-networks could be the future of how we connect](https://www.technologyreview.com/s/615094/why-private-micro-networks-could-be-the-future-of-how-we-connect/)
**Author**: Tanya Basu

**How I found this** from Skynet Today

**Summary**: this is a critique of current social media from the angle of oversharing. Current platforms, the author argues, are based around carefully cultivating your online image and broadcasting highlights of your life. It's not quite right for more close-knit communication. "Updating family about a vacation across platforms—via Instagram stories or on Facebook, for example—might not always be appropriate. Do you really want your cubicle pal, your acquaintance from book club, and your high school frenemy to be looped in as well?"

The social norms and wide-reaching audiences of platforms like Facebook, Instagram, and Twitter often make sharing inappropriate. Many people keep multiple accounts on these platforms (ever heard of finstas?) which are intended for different audiences. Micro-networks offer more control of your audience.

**Thoughts** this *kind of* reads like an advertisement for Cocoon, but I'll focus on the ideas behind it. I largely agree with the point here: despite social media aiming to connect people, it often feels impersonal. It's also the case that recent data mishaps have created a desire for a more privacy-focused, and perhaps more intimate, network. And platforms that optimize for engagement can create anxiety or otherwise [have unintended effects](https://dl.acm.org/doi/abs/10.1145/3351095.3372879), like on YouTube.

I'm not sure if something like Cocoon can take off. The free internet is supported by ads, and ads are so heavily ingrained in the norms of the internet that the idea of paying for online services seems outlandish. But I've recently found myself more willing to pay for ad-free, high-quality content (like [Stratechery](https://stratechery.com/), and I'm also considering [The Athletic](https://theathletic.com/) or [NYT / The Upshot](https://www.nytimes.com/section/upshot)), and I think this will slowly catch on.

Regardless, I appreciate this article for proposing a new alternative to the dominant social media platforms. The problems inherent in these platforms seem to be getting more obvious (maybe I'm just paying more attention), and questions about platform design are increasingly interesting to me.

## [The Democratic electorate on Twitter is not the actual Democratic electorate](https://www.nytimes.com/interactive/2019/04/08/upshot/democratic-electorate-twitter-real-life.html)
**Authors**: Nate Cohn and Kevin Quealy

**How I found this**: when trying to find the [Atlantic article](https://www.theatlantic.com/international/archive/2020/01/jeremy-corbyn-labour-twitter-primary/604690/) about the same topic

**Summary**: this is an article characterizing how the Democratic electorate on Twitter differs from the electorate off Twitter. It summarizes data from the [Hidden Tribes project](https://hiddentribes.us/). Some highlights:

 * 29% of Dems on social media identify as moderates or conservatives, but 53% of other Dems do
 * 48% of Dems on social media say political correctness is a problem in the US, compared to 70% of other Dems
 * 11% of Dems on social media are African American, compared to 24% of other Dems

Those who post on social media are also more likely to have a college degree, to be white, to have become more liberal throughout their life, and to donate to a political group. There are a number of other comparisons in the article, but the takeaway is that your average Twitter liberal is quantifiably different from your garden variety Democrat.

**Thoughts**: this is great, and absolutely consistent with my experience. Perhaps it's the trend of social media to create outrage, but I often see stark differences between Democrats who I follow online and those offline. The Hidden Tribes report is certainly something that I want to dig into in the future. To me, the message is clear: social media is warping our perception of what's normal.

## [So-So Artificial Intelligence](https://www.skynettoday.com/editorials/so-so-ai)
**Author**: Jessy Lin

**How I found this**: Skynet Today (on their website)

**Summary**: if we stop thinking about Artificial General Intelligence (AGI) for a moment, there are a lot of interesting questions about "narrow" task-specific AI. This article discusses what the authors call "so-so AI," talking about how many AI applications (like customer service chatbots or facial recognition) are just "so-so," but still disruptive enough to displace workers.

The author continued by discussing reasons for these trends, citing "the culture around AI in industry and academia" as the core concept. Research, the author argues, designs for humans *out* of the loop, meaning systems are rarely designed (and almost never evaluated) for humans to be working with them. 

**Thoughts**: this is very well argued. I love the concept of human-centered AI, and it's one of the broad research areas that I'm interested in. Designing AI to work with humans is a tough, interdisciplinary, and domain-specific problem. Some of the papers I've read recently have talked about possible human-in-the-loop applications of ML for online content moderation, and there are many other ideas out there too.

## Other, shorter articles
[Making Machine Learning Scalable and Accessible at Grubhub](https://bytes.grubhub.com/just-what-i-needed-making-machine-learning-scalable-and-accessible-at-grubhub-24734cc4139d) is an article from Grubhub's data science & MLE teams about the machine learning platform they've built. This is the latest in a long line of company-internal ML platforms, including [Uber's Michelangelo](https://eng.uber.com/michelangelo/), [Facebook's FBLearner Flow](https://engineering.fb.com/core-data/introducing-fblearner-flow-facebook-s-ai-backbone/), the one that I worked on at Nielsen, and more that I can't find. The article is a good read, but not much that I haven't seen before.

[Reflecting on our Python 2 to 3 Project](https://www.rover.com/blog/engineering/post/reflecting-on-our-python-2-to-3-project/) is an article about Rover's migration from Python 2 to 3. It is a followup to a previous post they wrote, [Moving Safely to Python 3](https://www.rover.com/blog/engineering/post/moving-safely-to-python-3/), nearly a year ago. 

[Applying mypy to real world projects](http://calpaterson.com/mypy-hints.html) is some nice, *practical* advice on mypy. It's more advanced than introductions or tutorials, and more practical than most resources I've seen. It links to the [Dropbox post](https://blogs.dropbox.com/tech/2019/09/our-journey-to-type-checking-4-million-lines-of-python/) on type checking their codebase, which is also a great read.


