+++
title = "What I read this week (June 28 - July 11)"
date = 2020-07-11
categories = ["what I read"]
draft = true
+++

This week, I watched a few talks from SciPy 2020 and continued my reading on *Twenty-Six Words*; this post mostly contains the talks.

<!--more-->

## [Talk] [JAX: Accelerated Machine Learning Research](https://www.youtube.com/watch?v=z-WSrQDXkuM)
**Speaker**: Jake VanderPlas

This talk, from (virtual) SciPy 2020, motivates, demos, and briefly explains JAX, a [Google library](https://github.com/google/jax/) for high-performance machine learning research. Loosely speaking, JAX is the NumPy API which is JIT compiled so that it can run faster and on different devices (GPUs or TPUs). 

The demo was slick. I had no idea that JAX could be 100x faster than normal NumPy for basic matrix multiplications! But what I found most interesting was the explanation of the "tracing" mechanism that they use for compiling functions. JAX sends "abstract values" through the functions to record what kind of object (meaning shape? I think?) each step will produce.

This was a great overview of JAX! I plan to recommend it to my team, which is using the JAX-backed [NumPyro](https://github.com/pyro-ppl/numpyro/), and other friends as well.


## [Talk] [Ray: A System for Scalable Python and ML](https://www.youtube.com/watch?v=XIu8ZF7RSkw)
**Speaker**: Robert Nishihara

This project introduces [Ray](https://github.com/ray-project/ray), a Python library for building distributed applications. The motivation was that existing distributed computing systems need tons of expertise to understand and use, and that the tools are becoming more specialized. Ray aims to be performant and general-purpose by providing higher-level abstractions than, say, Spark.

The core concepts appear to be wrapping functions and classes in a decorator, `@ray.remote()`, to turn them into tasks and actors respectively. These return futures asynchronously, rather than blocking execution, and Ray manages the scheduling overhead. Ray handles the overhead in setting up your remote processes (on e.g., AWS or GCP), distributing the workloads, and debugging and monitoring them via a dashboard.

Sounds cool! The story of async programming in Python has always been challenging, so I'm excited to see something new happening here. This was a good introduction to a library that I knew nothing about previously---great stuff!
