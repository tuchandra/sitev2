+++
title = "Papers that I never got around to"
date = 2020-10-19
draft = false
categories = ["self"]
+++

In an effort to clean up my reading list, this page catalogues papers that caught my eye but that I never got around to reading.

<!--more-->

I'd love to read all of these some day; like I said, they caught my eye at least once before.
But, being realistic with myself, I think it's important to accept that I can't get around to everything; I have limited time and energy.
Rather than maintain an indefinite list of "laters," I choose to put these papers to rest on this page.

I liken this to closing my browser tabs.
If something is truly engaging, I'll come back to it later.
But for now, I am accepting that I have no plans to read these, as great as they probably are.


## CHI 2020
When looking for papers to read, I used the following sources:
 * [Ali Alkhatib](https://ali-alkhatib.com/blog/chi-2020-reading-list): A (tentative) CHI Reading List
 * [CHI 2020 Best Papers & Honorable Mentions](https://chi2020.acm.org/for-attendees/chi-2020-best-papers-honourable-mentions/)
 * [Full Proceedings](https://dl.acm.org/doi/proceedings/10.1145/3313831)
 * [UW Interactive Data Lab](https://idl.cs.washington.edu/papers)
 * [Twitter thread](https://twitter.com/cfiesler/status/1255923012894781440) by Casey Fiesler
 * [Another Twitter thread](https://twitter.com/QVeraLiao/status/1257491523937034240) by Vera Liao
 * [ai4hci workshop](https://sites.google.com/view/ai4hci/accepted-papers)

And these all looked interesting to me:
 * [Wrex: A Unifed Programming-by-Example Interaction for Synthesizing Readable Code for Data Scientists](https://dl.acm.org/doi/abs/10.1145/3313831.3376442) by Ian Drosos, Titus Barik, Philip J. Guo, Robert DeLine, Sumit Gulwani
 * [A Probabilistic Grammar of Graphics](https://dl.acm.org/doi/abs/10.1145/3313831.3376466) (Xiaoying Pu & Matthew Kay)
 * [Social Comparison and Facebook](https://dl.acm.org/doi/abs/10.1145/3313831.3376482) (Moira Burke, Justin Cheng & Bethany de Gant)
 * [Characterizing Twitter Users Who Engage in Adversarial Interactions against Political Candidates](https://dl.acm.org/doi/abs/10.1145/3313831.3376548) (Yiqing Hua, Mor Naaman & Thomas Ristenpart)
 * [Questioning the AI: Informing Design Practices for Explainable AI User Experiences](https://dl.acm.org/doi/abs/10.1145/3313831.3376590) (Q. Vera Liao, Daniel Gruen & Sarah Miller)
 * [Explain like I am a Scientist: The Linguistic Barriers of Entry to r/science](https://dl.acm.org/doi/abs/10.1145/3313831.3376524)
 * [No Explainability without Accountability: An Empirical Study of Explanations and Feedback in Interactive ML](https://dl.acm.org/doi/abs/10.1145/3313831.3376624)
 * [Paths Explored, Paths Omitted, Paths Obscured: Decision Points & Selective Reporting in End-to-End Data Analysis](https://dl.acm.org/doi/abs/10.1145/3313831.3376533)
 * [Many Faced Hate: A Cross Platform Study of Content Framing and Information Sharing by Online Hate Groups](https://dl.acm.org/doi/abs/10.1145/3313831.3376456)


## ICWSM 2020
I identified these by looking through the proceedings at: https://aaai.org/ojs/index.php/ICWSM/issue/view/262.

[Communal Quirks and Circlejerks: A Taxonomy of Processes Contributing to Insularity in Online Communities](https://aaai.org/ojs/index.php/ICWSM/article/view/7275) by Kimberley Allison, Kay Bussey 

[Higher Ground? How Groundtruth Labeling Impacts Our Understanding of Fake News about the 2016 U.S. Presidential Nominees](https://aaai.org/ojs/index.php/ICWSM/article/view/7278) by Lia Bozarth, Aparajita Saraf, Ceren Budak

[Toward a Better Performance Evaluation Framework for Fake News Classification](https://aaai.org/ojs/index.php/ICWSM/article/view/7279) by Lia Bozarth, Ceren Budak 

[No Robots, Spiders, or Scrapers: Legal and Ethical Regulation of Data Collection Methods in Social Media Terms of Service](https://aaai.org/ojs/index.php/ICWSM/article/view/7290) by Casey Fiesler, Nathan Beard, Brian C. Keegan 

[Towards Measuring Adversarial Twitter Interactions against Candidates in the US Midterm Elections](https://aaai.org/ojs/index.php/ICWSM/article/view/7298) by Yiqing Hua, Thomas Ristenpart, Mor Naaman 

[Detecting Troll Behavior via Inverse Reinforcement Learning: A Case Study of Russian Trolls in the 2016 US Election](https://aaai.org/ojs/index.php/ICWSM/article/view/7311) by  Luca Luceri, Silvia Giordano, Emilio Ferrara 

[The Structure of U.S. College Networks on Facebook](https://aaai.org/ojs/index.php/ICWSM/article/view/7318) by Jan Overgoor, Bogdan State, Lada A. Adamic 


## Other papers
I don't plan to read these any time soon; but again, these all looked interesting at some point.

[On the Utility of Learning about Humans for Human-AI Coordination](https://arxiv.org/pdf/1910.05789.pdf) from BAIR, NeurIPS 2019

[Towards fairer datasets: filtering and balancing the distribution of the people subtree in the ImageNet hierarchy](https://arxiv.org/abs/1912.07726) from FAT* 2020

[Gelman: progress from the past decade](https://statmodeling.stat.columbia.edu/2020/01/01/progress-in-the-past-decade/) is a list of tons of papers on his blog

[Beyond near and long term: something about AI ethics and society](https://arxiv.org/abs/2001.04335) from Import AI

[The stealth media? Groups and targets behind divisive issue campaigns on Facebook](https://journalism.wisc.edu/wp-content/blogs.dir/41/files/2018/04/Kim.FB_.StealthMedia.re_.3.two-colmns.041718-1.pdf) from Network Propaganda

[Weaponizing the digital influence machine: the political perils of online ad tech](https://datasociety.net/wp-content/uploads/2018/10/DS_Digital_Influence_Machine.pdf) on digital political advertising


## ICML papers
From the [participatory design workshop](https://participatoryml.github.io/#):
 * Fairness, Equality, and Power in Algorithmic Decision-Making 
 * Measuring Non-Expert Comprehension of Machine Learning Fairness Metrics (Encore: ICML 2020) 
 * The Hidden Assumptions Behind Counterfactual Explanations and Principal Reasons (Encore: FAccT 2020) 
 * Metric-Free Individual Fairness in Online Learning 


## Blog posts, websites, etc.
Most things on [this course project page](https://courses.cs.washington.edu/courses/cse492e/20wi/project.html), found from the author of the Skynet Today article

[The coming software apocalypse](https://www.theatlantic.com/technology/archive/2017/09/saving-the-world-from-code/540393/) from The Atlantic. I've already read this, but worth revisiting.

[FAIR blog post](https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system) on insta recommendations, from Miranda

[An epidemic of AI misinformation](https://thegradient.pub/an-epidemic-of-ai-misinformation) from Data Elixir

[Overcooked blog post by BAIR](https://bair.berkeley.edu/blog/2019/10/21/coordination/), from Judah

